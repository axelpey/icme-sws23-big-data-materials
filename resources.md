# Links to readings & videos

### How much data is generated & who collects the most

- [How Much Data is Created Every Day in 2023? (Full Stats) » WP Dev Shed](https://wpdevshed.com/how-much-data-is-created-every-day/)
- [Amount of Data Created Daily (2023)](https://explodingtopics.com/blog/data-generated-per-day)
- [Study Shows Google Collects Most Data Out of All Big Tech Companies / Digital Information World](https://www.digitalinformationworld.com/2022/05/study-shows-google-collects-most-data.html)
- [The 7 Most Data-Rich Companies In The World?](https://www.linkedin.com/pulse/7-most-data-rich-companies-world-bernard-marr/)

### Future Outlook: The biggest company in the world (A16Z)

- [The Biggest Company in the World | Andreessen Horowitz](https://a16z.com/2022/11/11/the-biggest-company-in-the-world/)

### Largest data centers in the world

- [Largent data centers in the world](https://analyticsdrift.com/largest-data-centers-in-the-world/#:~:text=The%20Inner%20Mongolia%20Information%20Park,Tianjin%20economic%20circle%20radiation%20belt.)

### Database vs Data Lake vs Data Warehouse

- [Database vs Data Warehouse vs Data Lake | What is the Difference?](https://www.youtube.com/watch?v=-bSkREem8dM)
- [YOUTUBE - Data Warehouse vs. Data Lake Cheat Sheet](https://www.youtube.com/watch?v=TcgiZFZ-r1U)

### Distributed file system

- [What is a Distributed File System (DFS)?](https://www.techtarget.com/searchstorage/definition/distributed-file-system-DFS?Offer=abt_pubpro_AI-Insider)

### Stanford Education Data Archive

- [Stanford Education Data Archive (SEDA) - Research from Stanford University](https://exhibits.stanford.edu/data/catalog/db586ns4974)
- [Opportunity Explorer | The Educational Opportunity Project at Stanford University](https://edopportunity.org/explorer/#/map/none/districts/avg/ses/all/3.5/38/-97/)

# Other classes to take

## Introductory / Slower paced

[Coursera Big Data Specialization](https://www.coursera.org/specializations/big-data?#courses):

- Available online
- Relatively easy
- Available for free if you don’t want the certificate

## Advanced

[Stanford CS 224W: Machine Learning with Graphs](http://web.stanford.edu/class/cs224w/):

- Mostly available online
- Mostly delves into Graph Neural Networks, very useful if you want to learn to work with graphs data

[Stanford CS 246: Mining Massive Datasets](https://web.stanford.edu/class/cs246/index.html#content)

- Mostly available online
- Very useful to practice with Spark. Really a good course to ML on very large data.

# Cool datasets to explore (or websites)

The best way to learn is practice, and in Big Data the best way to practice is to get a dataset and play with it. On top of the ones we’ve explored in our workshop, here are a few others you might want to consider that are quite famous:

### The Netflix dataset:

https://www.kaggle.com/datasets/netflix-inc/netflix-prize-data

For the story, Netflix released this dataset in 2006 and put a huge reward to who would best do recommendations with it. You can learn more about it here: https://www.wikiwand.com/en/Netflix_Prize

### The Sentiment140 Dataset:

https://www.kaggle.com/datasets/kazanova/sentiment140

A very famous dataset to try to do sentiment analysis / prediction.

### Kaggle in general

The website on which the two datasets above were posted, is actually the main hub for posting datasets so that data-savvy people compete on some tasks with them.

# Additional Resources: Education Memo’s & Posters from AJ

Find the resources [here](https://drive.google.com/drive/folders/16ob8ldooBBHbDxQz8D1v-SjX-OlfEmL9?usp=sharing).

We provided 2 memos & 2 posters that can serve as examples for education research using (big) data. The examples provided were part of class projects and we do not guarantee full accuracy.

# ChatGPT: A brief overview

ChatGPT, along with all other LLMs getting released this year, is a revolution, and not just to write essays, but also to produce code and even help you work with data.

You can literally ask it to produce code to get the answer to a question by giving it the header of the data you have and in which type of database it is.

You can also use the new ChatGPT Code Interpreter to perform data analysis faster! See for examples: [https://www.logicloop.com/posts/chatgpt-code-interpreter-for-data-analysis] Be careful though, running code on Code Interpreter means also giving access to your data to OpenAI. Make sure you’re not sending anything sensitive.

Practice with what we have written in the colab for Day 2! The best way to use it, we’ve found, is to ask a question to it and also ask for the code to use to get it.

# Colabs

Day 1 - SQLite: [LINK](https://colab.research.google.com/drive/18wYOhTV22TjOb9BM0d7cbYNCHY6xk6Ws?usp=sharing)
Day 1 - NoSQL MongoDB: [LINK](https://colab.research.google.com/drive/1bGjIANBFyP2SvBkBTN-ks_Z5vjQ7ySTB?usp=sharing)

- Due to this notebook running only on my MongoDB account and it having been published already publicly on github, it does not contain credentials to read the database anymore. Only use it to see how the code and output can look like, but you won’t be able to execute the code.

Day 2 - PySpark: [LINK](https://drive.google.com/file/d/1iMynNjU4L7nWA2nvimZLUdlTqHwuRgxU/view?usp=sharing)
Day 2 - ChatGPT: Day 2 - [LINK](https://colab.research.google.com/drive/152TxOdpHBEjQWqUXA5YesW07ciPfjYKp?usp=sharing)
